{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd0aa981-955d-4a1b-a2e5-4ac9b086d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregamos el path para poder importar módulos personalizados\n",
    "import sys\n",
    "sys.path.append('/home/jovyan/work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1b384c6e-939c-4295-ab94-a8a9a4ed748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_loader import cargar_dataset\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d7efb8-73d9-4ade-ad66-6fa290d16e43",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **CARGAR DATOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a2606a5-46da-4530-ad80-bf93383fa1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estructura del dataset:\n",
      " Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 1801350\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el split de entrenamiento del dataset WikiText-103\n",
    "dataset = cargar_dataset(split=\"train\")\n",
    "\n",
    "# Visualizamos la estructura básica\n",
    "print(\"Estructura del dataset:\\n\", dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad91345-98ce-4e9d-92b7-a3dca40de72e",
   "metadata": {},
   "source": [
    "#### **VISUALIZACIÓN DE CONTENIDO DEL DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8e0a5fb-1dad-4669-86d4-e9d3792b3bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texto:\n",
      " {'text': ' = Valkyria Chronicles III = \\n'}\n",
      "\n",
      "Texto:\n",
      " {'text': ' Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" <unk> Raven \" . \\n'}\n",
      "\n",
      "Texto:\n",
      " {'text': \" The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer <unk> Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \\n\"}\n",
      "\n",
      "Texto:\n",
      " {'text': \" It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 . \\n\"}\n",
      "\n",
      "Texto:\n",
      " {'text': ' = = Gameplay = = \\n'}\n"
     ]
    }
   ],
   "source": [
    "# Mostramos las primeras 5 líneas no vacías del dataset\n",
    "count = 0\n",
    "sentences = []\n",
    "for sentence in dataset:\n",
    "    if sentence[\"text\"].strip():\n",
    "        sentences.append(sentence[\"text\"].strip())\n",
    "        print(\"\\nTexto:\\n\", sentence)\n",
    "        count += 1\n",
    "    if count == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404a5fc0-a5b0-494b-89b0-294cef2d8676",
   "metadata": {},
   "source": [
    "#### **TOKENIZACIÓN Y VOCABULARIO MANUAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47fed08d-d112-4cdf-aec6-996bd780e5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texto 1: ['=', 'valkyria', 'chronicles', 'iii', '=']\n",
      "\n",
      "Texto 2: ['senjō', 'no', 'valkyria', '3', ':', '<unk>', 'chronicles', '(', 'japanese', ':', '戦場のヴァルキュリア3', ',', 'lit', '.', 'valkyria', 'of', 'the', 'battlefield', '3', ')', ',', 'commonly', 'referred', 'to', 'as', 'valkyria', 'chronicles', 'iii', 'outside', 'japan', ',', 'is', 'a', 'tactical', 'role', '@-@', 'playing', 'video', 'game', 'developed', 'by', 'sega', 'and', 'media.vision', 'for', 'the', 'playstation', 'portable', '.', 'released', 'in', 'january', '2011', 'in', 'japan', ',', 'it', 'is', 'the', 'third', 'game', 'in', 'the', 'valkyria', 'series', '.', 'employing', 'the', 'same', 'fusion', 'of', 'tactical', 'and', 'real', '@-@', 'time', 'gameplay', 'as', 'its', 'predecessors', ',', 'the', 'story', 'runs', 'parallel', 'to', 'the', 'first', 'game', 'and', 'follows', 'the', '\"', 'nameless', '\"', ',', 'a', 'penal', 'military', 'unit', 'serving', 'the', 'nation', 'of', 'gallia', 'during', 'the', 'second', 'europan', 'war', 'who', 'perform', 'secret', 'black', 'operations', 'and', 'are', 'pitted', 'against', 'the', 'imperial', 'unit', '\"', '<unk>', 'raven', '\"', '.']\n",
      "\n",
      "Texto 3: ['the', 'game', 'began', 'development', 'in', '2010', ',', 'carrying', 'over', 'a', 'large', 'portion', 'of', 'the', 'work', 'done', 'on', 'valkyria', 'chronicles', 'ii', '.', 'while', 'it', 'retained', 'the', 'standard', 'features', 'of', 'the', 'series', ',', 'it', 'also', 'underwent', 'multiple', 'adjustments', ',', 'such', 'as', 'making', 'the', 'game', 'more', 'forgiving', 'for', 'series', 'newcomers', '.', 'character', 'designer', '<unk>', 'honjou', 'and', 'composer', 'hitoshi', 'sakimoto', 'both', 'returned', 'from', 'previous', 'entries', ',', 'along', 'with', 'valkyria', 'chronicles', 'ii', 'director', 'takeshi', 'ozawa', '.', 'a', 'large', 'team', 'of', 'writers', 'handled', 'the', 'script', '.', 'the', 'game', \"'s\", 'opening', 'theme', 'was', 'sung', 'by', 'may', \"'n\", '.']\n",
      "\n",
      "Texto 4: ['it', 'met', 'with', 'positive', 'sales', 'in', 'japan', ',', 'and', 'was', 'praised', 'by', 'both', 'japanese', 'and', 'western', 'critics', '.', 'after', 'release', ',', 'it', 'received', 'downloadable', 'content', ',', 'along', 'with', 'an', 'expanded', 'edition', 'in', 'november', 'of', 'that', 'year', '.', 'it', 'was', 'also', 'adapted', 'into', 'manga', 'and', 'an', 'original', 'video', 'animation', 'series', '.', 'due', 'to', 'low', 'sales', 'of', 'valkyria', 'chronicles', 'ii', ',', 'valkyria', 'chronicles', 'iii', 'was', 'not', 'localized', ',', 'but', 'a', 'fan', 'translation', 'compatible', 'with', 'the', 'game', \"'s\", 'expanded', 'edition', 'was', 'released', 'in', '2014', '.', 'media.vision', 'would', 'return', 'to', 'the', 'franchise', 'with', 'the', 'development', 'of', 'valkyria', ':', 'azure', 'revolution', 'for', 'the', 'playstation', '4', '.']\n",
      "\n",
      "Texto 5: ['=', '=', 'gameplay', '=', '=']\n",
      "\n",
      "Total de palabras en el vocabulario: 171\n",
      "\n",
      "Vocabulario inicial (manual):\n",
      "'the': 22\n",
      "',': 15\n",
      "'.': 14\n",
      "'valkyria': 10\n",
      "'of': 9\n",
      "'and': 8\n",
      "'chronicles': 7\n",
      "'game': 7\n",
      "'in': 7\n",
      "'=': 6\n",
      "'it': 6\n",
      "'a': 5\n",
      "'with': 5\n",
      "'was': 5\n",
      "'to': 4\n",
      "'series': 4\n",
      "'\"': 4\n",
      "'iii': 3\n",
      "':': 3\n",
      "'<unk>': 3\n",
      "'as': 3\n",
      "'japan': 3\n",
      "'by': 3\n",
      "'for': 3\n",
      "'ii': 3\n",
      "'3': 2\n",
      "'japanese': 2\n",
      "'is': 2\n",
      "'tactical': 2\n",
      "'@-@': 2\n",
      "'video': 2\n",
      "'media.vision': 2\n",
      "'playstation': 2\n",
      "'released': 2\n",
      "'gameplay': 2\n",
      "'unit': 2\n",
      "'development': 2\n",
      "'large': 2\n",
      "'also': 2\n",
      "'both': 2\n",
      "'along': 2\n",
      "''s': 2\n",
      "'sales': 2\n",
      "'an': 2\n",
      "'expanded': 2\n",
      "'edition': 2\n",
      "'senjō': 1\n",
      "'no': 1\n",
      "'(': 1\n",
      "'戦場のヴァルキュリア3': 1\n",
      "'lit': 1\n",
      "'battlefield': 1\n",
      "')': 1\n",
      "'commonly': 1\n",
      "'referred': 1\n",
      "'outside': 1\n",
      "'role': 1\n",
      "'playing': 1\n",
      "'developed': 1\n",
      "'sega': 1\n",
      "'portable': 1\n",
      "'january': 1\n",
      "'2011': 1\n",
      "'third': 1\n",
      "'employing': 1\n",
      "'same': 1\n",
      "'fusion': 1\n",
      "'real': 1\n",
      "'time': 1\n",
      "'its': 1\n",
      "'predecessors': 1\n",
      "'story': 1\n",
      "'runs': 1\n",
      "'parallel': 1\n",
      "'first': 1\n",
      "'follows': 1\n",
      "'nameless': 1\n",
      "'penal': 1\n",
      "'military': 1\n",
      "'serving': 1\n",
      "'nation': 1\n",
      "'gallia': 1\n",
      "'during': 1\n",
      "'second': 1\n",
      "'europan': 1\n",
      "'war': 1\n",
      "'who': 1\n",
      "'perform': 1\n",
      "'secret': 1\n",
      "'black': 1\n",
      "'operations': 1\n",
      "'are': 1\n",
      "'pitted': 1\n",
      "'against': 1\n",
      "'imperial': 1\n",
      "'raven': 1\n",
      "'began': 1\n",
      "'2010': 1\n",
      "'carrying': 1\n",
      "'over': 1\n",
      "'portion': 1\n",
      "'work': 1\n",
      "'done': 1\n",
      "'on': 1\n",
      "'while': 1\n",
      "'retained': 1\n",
      "'standard': 1\n",
      "'features': 1\n",
      "'underwent': 1\n",
      "'multiple': 1\n",
      "'adjustments': 1\n",
      "'such': 1\n",
      "'making': 1\n",
      "'more': 1\n",
      "'forgiving': 1\n",
      "'newcomers': 1\n",
      "'character': 1\n",
      "'designer': 1\n",
      "'honjou': 1\n",
      "'composer': 1\n",
      "'hitoshi': 1\n",
      "'sakimoto': 1\n",
      "'returned': 1\n",
      "'from': 1\n",
      "'previous': 1\n",
      "'entries': 1\n",
      "'director': 1\n",
      "'takeshi': 1\n",
      "'ozawa': 1\n",
      "'team': 1\n",
      "'writers': 1\n",
      "'handled': 1\n",
      "'script': 1\n",
      "'opening': 1\n",
      "'theme': 1\n",
      "'sung': 1\n",
      "'may': 1\n",
      "''n': 1\n",
      "'met': 1\n",
      "'positive': 1\n",
      "'praised': 1\n",
      "'western': 1\n",
      "'critics': 1\n",
      "'after': 1\n",
      "'release': 1\n",
      "'received': 1\n",
      "'downloadable': 1\n",
      "'content': 1\n",
      "'november': 1\n",
      "'that': 1\n",
      "'year': 1\n",
      "'adapted': 1\n",
      "'into': 1\n",
      "'manga': 1\n",
      "'original': 1\n",
      "'animation': 1\n",
      "'due': 1\n",
      "'low': 1\n",
      "'not': 1\n",
      "'localized': 1\n",
      "'but': 1\n",
      "'fan': 1\n",
      "'translation': 1\n",
      "'compatible': 1\n",
      "'2014': 1\n",
      "'would': 1\n",
      "'return': 1\n",
      "'franchise': 1\n",
      "'azure': 1\n",
      "'revolution': 1\n",
      "'4': 1\n"
     ]
    }
   ],
   "source": [
    "# Definimos un tokenizador básico que separa por espacios y pasa todo a minúsculas\n",
    "def custom_tokenizer(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "# Aplicamos tokenización a las 5 oraciones capturadas\n",
    "for i, s in enumerate(sentences):\n",
    "    tokens = custom_tokenizer(s)\n",
    "    print(f\"\\nTexto {i+1}: {tokens}\")\n",
    "\n",
    "# Construimos un vocabulario manual usando Counter\n",
    "word_vocab = Counter()\n",
    "\n",
    "for s in sentences:\n",
    "    tokens = custom_tokenizer(s)\n",
    "    word_vocab.update(tokens)\n",
    "\n",
    "# Mostramos el tamaño del vocabulario y las palabras más frecuentes\n",
    "print(f\"\\nTotal de palabras en el vocabulario: {len(word_vocab)}\")\n",
    "print(\"\\nVocabulario inicial (manual):\")\n",
    "for word, freq in word_vocab.most_common():\n",
    "    print(f\"'{word}': {freq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3988fc7d-fa7e-4cf1-8dff-b4f8419f87ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### **TOKENIZACIÓN Y VOCABULARIO USANDO TORCHTEXT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2d5f63-88f9-4195-a20d-d4a2100dfdf4",
   "metadata": {},
   "source": [
    "##### **Definición de tokenizador y construcción de vocabulario**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ef0277b-eb05-4979-a7f4-44983b14fec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario construido con 171 tokens\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "# Tokenizador\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "# Construir el vocabulario\n",
    "vocab = build_vocab_from_iterator(map(tokenizer, sentences))\n",
    "\n",
    "print(f\"Vocabulario construido con {len(vocab)} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dfe1f4-2d15-4477-9f6e-60626ef04f3a",
   "metadata": {},
   "source": [
    "##### **Definición de conjunto de datos personalizado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f00a1b26-e61a-41bb-9140-46ae3313eb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del conjunto de datos personalizado: 5\n",
      "Items de muestra:\n",
      "Item 1: tensor([ 9,  3,  6, 22,  9])\n",
      "Item 2: tensor([148, 110,   3,  24,  17,   6,  46,  35, 170,   2,  96,   1,   3,   4,\n",
      "          0,  59,  24,  47,   2,  65, 134,  15,  18,   3,   6,  22, 117,  23,\n",
      "          2,  34,  11,  42, 140,  25, 124,  44,   7,  71,  19, 147,   5,  37,\n",
      "          1,  45,  20,   0,  38, 125,   1,  39,   8,  95,  49,   8,  23,   2,\n",
      "         10,  34,   0, 158,   7,   8,   0,   3,  14,   1,  77,   0, 143,  87,\n",
      "          4,  42,   5, 132,  25, 159,  33,  18,  94, 129,   2,   0, 151, 141,\n",
      "        120,  15,   0,  82,   7,   5,  83,   0, 107,   2,  11, 121, 103,  43,\n",
      "        149,   0, 108,   4,  88,  76,   0, 145,  79, 162, 165, 122, 146,  61,\n",
      "        115,   5,  57, 123,  55,   0,  92,  43,  17, 131,   1])\n",
      "Item 3: tensor([  0,   7,  60,  30,   8,  48,   2,  63, 118,  11,  36, 126,   4,   0,\n",
      "        166,  73, 113,   3,   6,  21,   1, 164,  10, 136,   0, 150,  81,   4,\n",
      "          0,  14,   2,  10,  27, 161, 105,  53,   2, 152,  18,  99,   0,   7,\n",
      "        104,  84,  20,  14, 109,   1,  64,  70,  17,  91,   5,  67,  90, 142,\n",
      "         29, 138,  86, 130,  78,   2,  26,  13,   3,   6,  21,  72, 154, 119,\n",
      "          1,  11,  36, 155,   4, 168,  89,   0, 144,   1,   0,   7,  16,  40,\n",
      "        114, 157,  12, 153,  19, 101,  16, 106,   1])\n",
      "Item 4: tensor([ 10, 102,  13, 127,  41,   8,  23,   2,   5,  12, 128,  19,  29,  35,\n",
      "          5, 163,  69,   1,  54, 135,   2,  10, 133,  74,  68,   2,  26,  13,\n",
      "         28,  32,  31,   8, 112,   4, 156, 169,   1,  10,  12,  27,  52,  93,\n",
      "        100,   5,  28, 116,  44,  56,  14,   1,  75,  15,  98,  41,   4,   3,\n",
      "          6,  21,   2,   3,   6,  22,  12, 111,  97,   2,  62,  11,  80, 160,\n",
      "         66,  13,   0,   7,  16,  40,  32,  31,  12,  39,   8,  50,   1,  37,\n",
      "          1,  45, 167, 137,  15,   0,  85,  13,   0,  30,   4,   3,  58, 139,\n",
      "         20,   0,  38,  51,   1])\n",
      "Item 5: tensor([ 9,  9, 33,  9,  9])\n"
     ]
    }
   ],
   "source": [
    "# Definir un conjunto de datos personalizado\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, sentences, tokenizer, vocab):\n",
    "        self.sentences = sentences\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokens = self.tokenizer(self.sentences[idx])\n",
    "        # Convertir tokens a índices de tensor usando el vocabulario\n",
    "        tensor_indices = [self.vocab[token] for token in tokens]\n",
    "        return torch.tensor(tensor_indices)\n",
    "    \n",
    "# Crear una instancia de tu conjunto de datos personalizado\n",
    "custom_dataset = CustomDataset(sentences, tokenizer, vocab)\n",
    "\n",
    "print(\"Longitud del conjunto de datos personalizado:\", len(custom_dataset))\n",
    "print(\"Items de muestra:\")\n",
    "\n",
    "for i in range(5):\n",
    "    sample_item = custom_dataset[i]\n",
    "    print(f\"Item {i + 1}: {sample_item}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fdbcf9-de2d-4f60-af55-c185e80b995f",
   "metadata": {},
   "source": [
    "##### **Reconstrucción de texto a partir de índices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48f4eb5f-4fd5-4806-91e8-64a5732b1fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Textos procesados (reconstruidos):\n",
      "\n",
      "Texto 1: ['=', 'valkyria', 'chronicles', 'iii', '=']\n",
      "\n",
      "Texto 2: ['senjō', 'no', 'valkyria', '3', '<unk>', 'chronicles', '(', 'japanese', '戦場のヴァルキュリア3', ',', 'lit', '.', 'valkyria', 'of', 'the', 'battlefield', '3', ')', ',', 'commonly', 'referred', 'to', 'as', 'valkyria', 'chronicles', 'iii', 'outside', 'japan', ',', 'is', 'a', 'tactical', 'role', '@-@', 'playing', 'video', 'game', 'developed', 'by', 'sega', 'and', 'media', '.', 'vision', 'for', 'the', 'playstation', 'portable', '.', 'released', 'in', 'january', '2011', 'in', 'japan', ',', 'it', 'is', 'the', 'third', 'game', 'in', 'the', 'valkyria', 'series', '.', 'employing', 'the', 'same', 'fusion', 'of', 'tactical', 'and', 'real', '@-@', 'time', 'gameplay', 'as', 'its', 'predecessors', ',', 'the', 'story', 'runs', 'parallel', 'to', 'the', 'first', 'game', 'and', 'follows', 'the', 'nameless', ',', 'a', 'penal', 'military', 'unit', 'serving', 'the', 'nation', 'of', 'gallia', 'during', 'the', 'second', 'europan', 'war', 'who', 'perform', 'secret', 'black', 'operations', 'and', 'are', 'pitted', 'against', 'the', 'imperial', 'unit', '<unk>', 'raven', '.']\n",
      "\n",
      "Texto 3: ['the', 'game', 'began', 'development', 'in', '2010', ',', 'carrying', 'over', 'a', 'large', 'portion', 'of', 'the', 'work', 'done', 'on', 'valkyria', 'chronicles', 'ii', '.', 'while', 'it', 'retained', 'the', 'standard', 'features', 'of', 'the', 'series', ',', 'it', 'also', 'underwent', 'multiple', 'adjustments', ',', 'such', 'as', 'making', 'the', 'game', 'more', 'forgiving', 'for', 'series', 'newcomers', '.', 'character', 'designer', '<unk>', 'honjou', 'and', 'composer', 'hitoshi', 'sakimoto', 'both', 'returned', 'from', 'previous', 'entries', ',', 'along', 'with', 'valkyria', 'chronicles', 'ii', 'director', 'takeshi', 'ozawa', '.', 'a', 'large', 'team', 'of', 'writers', 'handled', 'the', 'script', '.', 'the', 'game', \"'\", 's', 'opening', 'theme', 'was', 'sung', 'by', 'may', \"'\", 'n', '.']\n",
      "\n",
      "Texto 4: ['it', 'met', 'with', 'positive', 'sales', 'in', 'japan', ',', 'and', 'was', 'praised', 'by', 'both', 'japanese', 'and', 'western', 'critics', '.', 'after', 'release', ',', 'it', 'received', 'downloadable', 'content', ',', 'along', 'with', 'an', 'expanded', 'edition', 'in', 'november', 'of', 'that', 'year', '.', 'it', 'was', 'also', 'adapted', 'into', 'manga', 'and', 'an', 'original', 'video', 'animation', 'series', '.', 'due', 'to', 'low', 'sales', 'of', 'valkyria', 'chronicles', 'ii', ',', 'valkyria', 'chronicles', 'iii', 'was', 'not', 'localized', ',', 'but', 'a', 'fan', 'translation', 'compatible', 'with', 'the', 'game', \"'\", 's', 'expanded', 'edition', 'was', 'released', 'in', '2014', '.', 'media', '.', 'vision', 'would', 'return', 'to', 'the', 'franchise', 'with', 'the', 'development', 'of', 'valkyria', 'azure', 'revolution', 'for', 'the', 'playstation', '4', '.']\n",
      "\n",
      "Texto 5: ['=', '=', 'gameplay', '=', '=']\n"
     ]
    }
   ],
   "source": [
    "# Función para convertir índices de vuelta a palabras\n",
    "def indices_a_palabras(indices, vocab):\n",
    "    return [vocab.get_itos()[idx] for idx in indices]\n",
    "\n",
    "# Mostramos los textos reconstruidos\n",
    "print(\"\\nTextos procesados (reconstruidos):\")\n",
    "\n",
    "for i in range(5):\n",
    "    sample_item = custom_dataset[i]\n",
    "    palabras = indices_a_palabras(sample_item.tolist(), vocab)\n",
    "    print(f\"\\nTexto {i+1}: {palabras}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c00f8ac-7bea-4099-8a43-2c7d7fae0756",
   "metadata": {},
   "source": [
    "##### **Cálculo de palabras más frecuentes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82e9082a-eba3-4103-b2e8-60ae2d34c09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de palabras en el vocabulario: 171\n",
      "Palabras más frecuentes:\n",
      "'the': 22\n",
      "'.': 16\n",
      "',': 15\n",
      "'valkyria': 10\n",
      "'of': 9\n",
      "'and': 8\n",
      "'chronicles': 7\n",
      "'game': 7\n",
      "'in': 7\n",
      "'=': 6\n",
      "'it': 6\n",
      "'a': 5\n",
      "'with': 5\n",
      "'was': 5\n",
      "'to': 4\n",
      "'series': 4\n",
      "'iii': 3\n",
      "'<unk>': 3\n",
      "'as': 3\n",
      "'japan': 3\n",
      "'by': 3\n",
      "'for': 3\n",
      "'ii': 3\n",
      "''': 3\n",
      "'3': 2\n",
      "'japanese': 2\n",
      "'is': 2\n",
      "'tactical': 2\n",
      "'@-@': 2\n",
      "'video': 2\n",
      "'media': 2\n",
      "'vision': 2\n",
      "'playstation': 2\n",
      "'released': 2\n",
      "'gameplay': 2\n",
      "'unit': 2\n",
      "'development': 2\n",
      "'large': 2\n",
      "'also': 2\n",
      "'both': 2\n",
      "'along': 2\n",
      "'s': 2\n",
      "'sales': 2\n",
      "'an': 2\n",
      "'expanded': 2\n",
      "'edition': 2\n",
      "'senjō': 1\n",
      "'no': 1\n",
      "'(': 1\n",
      "'戦場のヴァルキュリア3': 1\n",
      "'lit': 1\n",
      "'battlefield': 1\n",
      "')': 1\n",
      "'commonly': 1\n",
      "'referred': 1\n",
      "'outside': 1\n",
      "'role': 1\n",
      "'playing': 1\n",
      "'developed': 1\n",
      "'sega': 1\n",
      "'portable': 1\n",
      "'january': 1\n",
      "'2011': 1\n",
      "'third': 1\n",
      "'employing': 1\n",
      "'same': 1\n",
      "'fusion': 1\n",
      "'real': 1\n",
      "'time': 1\n",
      "'its': 1\n",
      "'predecessors': 1\n",
      "'story': 1\n",
      "'runs': 1\n",
      "'parallel': 1\n",
      "'first': 1\n",
      "'follows': 1\n",
      "'nameless': 1\n",
      "'penal': 1\n",
      "'military': 1\n",
      "'serving': 1\n",
      "'nation': 1\n",
      "'gallia': 1\n",
      "'during': 1\n",
      "'second': 1\n",
      "'europan': 1\n",
      "'war': 1\n",
      "'who': 1\n",
      "'perform': 1\n",
      "'secret': 1\n",
      "'black': 1\n",
      "'operations': 1\n",
      "'are': 1\n",
      "'pitted': 1\n",
      "'against': 1\n",
      "'imperial': 1\n",
      "'raven': 1\n",
      "'began': 1\n",
      "'2010': 1\n",
      "'carrying': 1\n",
      "'over': 1\n",
      "'portion': 1\n",
      "'work': 1\n",
      "'done': 1\n",
      "'on': 1\n",
      "'while': 1\n",
      "'retained': 1\n",
      "'standard': 1\n",
      "'features': 1\n",
      "'underwent': 1\n",
      "'multiple': 1\n",
      "'adjustments': 1\n",
      "'such': 1\n",
      "'making': 1\n",
      "'more': 1\n",
      "'forgiving': 1\n",
      "'newcomers': 1\n",
      "'character': 1\n",
      "'designer': 1\n",
      "'honjou': 1\n",
      "'composer': 1\n",
      "'hitoshi': 1\n",
      "'sakimoto': 1\n",
      "'returned': 1\n",
      "'from': 1\n",
      "'previous': 1\n",
      "'entries': 1\n",
      "'director': 1\n",
      "'takeshi': 1\n",
      "'ozawa': 1\n",
      "'team': 1\n",
      "'writers': 1\n",
      "'handled': 1\n",
      "'script': 1\n",
      "'opening': 1\n",
      "'theme': 1\n",
      "'sung': 1\n",
      "'may': 1\n",
      "'n': 1\n",
      "'met': 1\n",
      "'positive': 1\n",
      "'praised': 1\n",
      "'western': 1\n",
      "'critics': 1\n",
      "'after': 1\n",
      "'release': 1\n",
      "'received': 1\n",
      "'downloadable': 1\n",
      "'content': 1\n",
      "'november': 1\n",
      "'that': 1\n",
      "'year': 1\n",
      "'adapted': 1\n",
      "'into': 1\n",
      "'manga': 1\n",
      "'original': 1\n",
      "'animation': 1\n",
      "'due': 1\n",
      "'low': 1\n",
      "'not': 1\n",
      "'localized': 1\n",
      "'but': 1\n",
      "'fan': 1\n",
      "'translation': 1\n",
      "'compatible': 1\n",
      "'2014': 1\n",
      "'would': 1\n",
      "'return': 1\n",
      "'franchise': 1\n",
      "'azure': 1\n",
      "'revolution': 1\n",
      "'4': 1\n"
     ]
    }
   ],
   "source": [
    "# Calculamos la frecuencia de las palabras usando el vocabulario de torchtext\n",
    "palabras_frecuentes = {}\n",
    "\n",
    "for sentence in sentences:\n",
    "    tokens = tokenizer(sentence)\n",
    "    for token in tokens:\n",
    "        if token in vocab.get_stoi():\n",
    "            palabras_frecuentes[token] = palabras_frecuentes.get(token, 0) + 1\n",
    "\n",
    "# Mostramos el vocabulario y su frecuencia\n",
    "print(f\"Total de palabras en el vocabulario: {len(palabras_frecuentes)}\")\n",
    "print(\"Palabras más frecuentes:\")\n",
    "\n",
    "for palabra, frecuencia in sorted(palabras_frecuentes.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"'{palabra}': {frecuencia}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7329ef7-b926-4a18-bb94-b27e6cc4c987",
   "metadata": {},
   "source": [
    "#### **TOKENIZACIÓN Y VOCABULARIO MANUAL A NIVEL DE CARACTERES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "238169d2-0d0d-4cf3-9fb2-1d7daef99ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texto 1: = Valkyria Chronicles III =\n",
      "Tokenizada por caracteres 1: ['=', ' ', 'v', 'a', 'l', 'k', 'y', 'r', 'i', 'a', ' ', 'c', 'h', 'r', 'o', 'n', 'i', 'c', 'l', 'e', 's', ' ', 'i', 'i', 'i', ' ', '=']\n",
      "\n",
      "Texto 2: Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" <unk> Raven \" .\n",
      "Tokenizada por caracteres 2: ['s', 'e', 'n', 'j', 'ō', ' ', 'n', 'o', ' ', 'v', 'a', 'l', 'k', 'y', 'r', 'i', 'a', ' ', '3', ' ', ':', ' ', '<', 'u', 'n', 'k', '>', ' ', 'c', 'h', 'r', 'o', 'n', 'i', 'c', 'l', 'e', 's', ' ', '(', ' ', 'j', 'a', 'p', 'a', 'n', 'e', 's', 'e', ' ', ':', ' ', '戦', '場', 'の', 'ヴ', 'ァ', 'ル', 'キ', 'ュ', 'リ', 'ア', '3', ' ', ',', ' ', 'l', 'i', 't', ' ', '.', ' ', 'v', 'a', 'l', 'k', 'y', 'r', 'i', 'a', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'b', 'a', 't', 't', 'l', 'e', 'f', 'i', 'e', 'l', 'd', ' ', '3', ' ', ')', ' ', ',', ' ', 'c', 'o', 'm', 'm', 'o', 'n', 'l', 'y', ' ', 'r', 'e', 'f', 'e', 'r', 'r', 'e', 'd', ' ', 't', 'o', ' ', 'a', 's', ' ', 'v', 'a', 'l', 'k', 'y', 'r', 'i', 'a', ' ', 'c', 'h', 'r', 'o', 'n', 'i', 'c', 'l', 'e', 's', ' ', 'i', 'i', 'i', ' ', 'o', 'u', 't', 's', 'i', 'd', 'e', ' ', 'j', 'a', 'p', 'a', 'n', ' ', ',', ' ', 'i', 's', ' ', 'a', ' ', 't', 'a', 'c', 't', 'i', 'c', 'a', 'l', ' ', 'r', 'o', 'l', 'e', ' ', '@', '-', '@', ' ', 'p', 'l', 'a', 'y', 'i', 'n', 'g', ' ', 'v', 'i', 'd', 'e', 'o', ' ', 'g', 'a', 'm', 'e', ' ', 'd', 'e', 'v', 'e', 'l', 'o', 'p', 'e', 'd', ' ', 'b', 'y', ' ', 's', 'e', 'g', 'a', ' ', 'a', 'n', 'd', ' ', 'm', 'e', 'd', 'i', 'a', '.', 'v', 'i', 's', 'i', 'o', 'n', ' ', 'f', 'o', 'r', ' ', 't', 'h', 'e', ' ', 'p', 'l', 'a', 'y', 's', 't', 'a', 't', 'i', 'o', 'n', ' ', 'p', 'o', 'r', 't', 'a', 'b', 'l', 'e', ' ', '.', ' ', 'r', 'e', 'l', 'e', 'a', 's', 'e', 'd', ' ', 'i', 'n', ' ', 'j', 'a', 'n', 'u', 'a', 'r', 'y', ' ', '2', '0', '1', '1', ' ', 'i', 'n', ' ', 'j', 'a', 'p', 'a', 'n', ' ', ',', ' ', 'i', 't', ' ', 'i', 's', ' ', 't', 'h', 'e', ' ', 't', 'h', 'i', 'r', 'd', ' ', 'g', 'a', 'm', 'e', ' ', 'i', 'n', ' ', 't', 'h', 'e', ' ', 'v', 'a', 'l', 'k', 'y', 'r', 'i', 'a', ' ', 's', 'e', 'r', 'i', 'e', 's', ' ', '.', ' ', 'e', 'm', 'p', 'l', 'o', 'y', 'i', 'n', 'g', ' ', 't', 'h', 'e', ' ', 's', 'a', 'm', 'e', ' ', 'f', 'u', 's', 'i', 'o', 'n', ' ', 'o', 'f', ' ', 't', 'a', 'c', 't', 'i', 'c', 'a', 'l', ' ', 'a', 'n', 'd', ' ', 'r', 'e', 'a', 'l', ' ', '@', '-', '@', ' ', 't', 'i', 'm', 'e', ' ', 'g', 'a', 'm', 'e', 'p', 'l', 'a', 'y', ' ', 'a', 's', ' ', 'i', 't', 's', ' ', 'p', 'r', 'e', 'd', 'e', 'c', 'e', 's', 's', 'o', 'r', 's', ' ', ',', ' ', 't', 'h', 'e', ' ', 's', 't', 'o', 'r', 'y', ' ', 'r', 'u', 'n', 's', ' ', 'p', 'a', 'r', 'a', 'l', 'l', 'e', 'l', ' ', 't', 'o', ' ', 't', 'h', 'e', ' ', 'f', 'i', 'r', 's', 't', ' ', 'g', 'a', 'm', 'e', ' ', 'a', 'n', 'd', ' ', 'f', 'o', 'l', 'l', 'o', 'w', 's', ' ', 't', 'h', 'e', ' ', '\"', ' ', 'n', 'a', 'm', 'e', 'l', 'e', 's', 's', ' ', '\"', ' ', ',', ' ', 'a', ' ', 'p', 'e', 'n', 'a', 'l', ' ', 'm', 'i', 'l', 'i', 't', 'a', 'r', 'y', ' ', 'u', 'n', 'i', 't', ' ', 's', 'e', 'r', 'v', 'i', 'n', 'g', ' ', 't', 'h', 'e', ' ', 'n', 'a', 't', 'i', 'o', 'n', ' ', 'o', 'f', ' ', 'g', 'a', 'l', 'l', 'i', 'a', ' ', 'd', 'u', 'r', 'i', 'n', 'g', ' ', 't', 'h', 'e', ' ', 's', 'e', 'c', 'o', 'n', 'd', ' ', 'e', 'u', 'r', 'o', 'p', 'a', 'n', ' ', 'w', 'a', 'r', ' ', 'w', 'h', 'o', ' ', 'p', 'e', 'r', 'f', 'o', 'r', 'm', ' ', 's', 'e', 'c', 'r', 'e', 't', ' ', 'b', 'l', 'a', 'c', 'k', ' ', 'o', 'p', 'e', 'r', 'a', 't', 'i', 'o', 'n', 's', ' ', 'a', 'n', 'd', ' ', 'a', 'r', 'e', ' ', 'p', 'i', 't', 't', 'e', 'd', ' ', 'a', 'g', 'a', 'i', 'n', 's', 't', ' ', 't', 'h', 'e', ' ', 'i', 'm', 'p', 'e', 'r', 'i', 'a', 'l', ' ', 'u', 'n', 'i', 't', ' ', '\"', ' ', '<', 'u', 'n', 'k', '>', ' ', 'r', 'a', 'v', 'e', 'n', ' ', '\"', ' ', '.']\n",
      "\n",
      "Texto 3: The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer <unk> Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n .\n",
      "Tokenizada por caracteres 3: ['t', 'h', 'e', ' ', 'g', 'a', 'm', 'e', ' ', 'b', 'e', 'g', 'a', 'n', ' ', 'd', 'e', 'v', 'e', 'l', 'o', 'p', 'm', 'e', 'n', 't', ' ', 'i', 'n', ' ', '2', '0', '1', '0', ' ', ',', ' ', 'c', 'a', 'r', 'r', 'y', 'i', 'n', 'g', ' ', 'o', 'v', 'e', 'r', ' ', 'a', ' ', 'l', 'a', 'r', 'g', 'e', ' ', 'p', 'o', 'r', 't', 'i', 'o', 'n', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'w', 'o', 'r', 'k', ' ', 'd', 'o', 'n', 'e', ' ', 'o', 'n', ' ', 'v', 'a', 'l', 'k', 'y', 'r', 'i', 'a', ' ', 'c', 'h', 'r', 'o', 'n', 'i', 'c', 'l', 'e', 's', ' ', 'i', 'i', ' ', '.', ' ', 'w', 'h', 'i', 'l', 'e', ' ', 'i', 't', ' ', 'r', 'e', 't', 'a', 'i', 'n', 'e', 'd', ' ', 't', 'h', 'e', ' ', 's', 't', 'a', 'n', 'd', 'a', 'r', 'd', ' ', 'f', 'e', 'a', 't', 'u', 'r', 'e', 's', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 's', 'e', 'r', 'i', 'e', 's', ' ', ',', ' ', 'i', 't', ' ', 'a', 'l', 's', 'o', ' ', 'u', 'n', 'd', 'e', 'r', 'w', 'e', 'n', 't', ' ', 'm', 'u', 'l', 't', 'i', 'p', 'l', 'e', ' ', 'a', 'd', 'j', 'u', 's', 't', 'm', 'e', 'n', 't', 's', ' ', ',', ' ', 's', 'u', 'c', 'h', ' ', 'a', 's', ' ', 'm', 'a', 'k', 'i', 'n', 'g', ' ', 't', 'h', 'e', ' ', 'g', 'a', 'm', 'e', ' ', 'm', 'o', 'r', 'e', ' ', 'f', 'o', 'r', 'g', 'i', 'v', 'i', 'n', 'g', ' ', 'f', 'o', 'r', ' ', 's', 'e', 'r', 'i', 'e', 's', ' ', 'n', 'e', 'w', 'c', 'o', 'm', 'e', 'r', 's', ' ', '.', ' ', 'c', 'h', 'a', 'r', 'a', 'c', 't', 'e', 'r', ' ', 'd', 'e', 's', 'i', 'g', 'n', 'e', 'r', ' ', '<', 'u', 'n', 'k', '>', ' ', 'h', 'o', 'n', 'j', 'o', 'u', ' ', 'a', 'n', 'd', ' ', 'c', 'o', 'm', 'p', 'o', 's', 'e', 'r', ' ', 'h', 'i', 't', 'o', 's', 'h', 'i', ' ', 's', 'a', 'k', 'i', 'm', 'o', 't', 'o', ' ', 'b', 'o', 't', 'h', ' ', 'r', 'e', 't', 'u', 'r', 'n', 'e', 'd', ' ', 'f', 'r', 'o', 'm', ' ', 'p', 'r', 'e', 'v', 'i', 'o', 'u', 's', ' ', 'e', 'n', 't', 'r', 'i', 'e', 's', ' ', ',', ' ', 'a', 'l', 'o', 'n', 'g', ' ', 'w', 'i', 't', 'h', ' ', 'v', 'a', 'l', 'k', 'y', 'r', 'i', 'a', ' ', 'c', 'h', 'r', 'o', 'n', 'i', 'c', 'l', 'e', 's', ' ', 'i', 'i', ' ', 'd', 'i', 'r', 'e', 'c', 't', 'o', 'r', ' ', 't', 'a', 'k', 'e', 's', 'h', 'i', ' ', 'o', 'z', 'a', 'w', 'a', ' ', '.', ' ', 'a', ' ', 'l', 'a', 'r', 'g', 'e', ' ', 't', 'e', 'a', 'm', ' ', 'o', 'f', ' ', 'w', 'r', 'i', 't', 'e', 'r', 's', ' ', 'h', 'a', 'n', 'd', 'l', 'e', 'd', ' ', 't', 'h', 'e', ' ', 's', 'c', 'r', 'i', 'p', 't', ' ', '.', ' ', 't', 'h', 'e', ' ', 'g', 'a', 'm', 'e', ' ', \"'\", 's', ' ', 'o', 'p', 'e', 'n', 'i', 'n', 'g', ' ', 't', 'h', 'e', 'm', 'e', ' ', 'w', 'a', 's', ' ', 's', 'u', 'n', 'g', ' ', 'b', 'y', ' ', 'm', 'a', 'y', ' ', \"'\", 'n', ' ', '.']\n",
      "\n",
      "Texto 4: It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 .\n",
      "Tokenizada por caracteres 4: ['i', 't', ' ', 'm', 'e', 't', ' ', 'w', 'i', 't', 'h', ' ', 'p', 'o', 's', 'i', 't', 'i', 'v', 'e', ' ', 's', 'a', 'l', 'e', 's', ' ', 'i', 'n', ' ', 'j', 'a', 'p', 'a', 'n', ' ', ',', ' ', 'a', 'n', 'd', ' ', 'w', 'a', 's', ' ', 'p', 'r', 'a', 'i', 's', 'e', 'd', ' ', 'b', 'y', ' ', 'b', 'o', 't', 'h', ' ', 'j', 'a', 'p', 'a', 'n', 'e', 's', 'e', ' ', 'a', 'n', 'd', ' ', 'w', 'e', 's', 't', 'e', 'r', 'n', ' ', 'c', 'r', 'i', 't', 'i', 'c', 's', ' ', '.', ' ', 'a', 'f', 't', 'e', 'r', ' ', 'r', 'e', 'l', 'e', 'a', 's', 'e', ' ', ',', ' ', 'i', 't', ' ', 'r', 'e', 'c', 'e', 'i', 'v', 'e', 'd', ' ', 'd', 'o', 'w', 'n', 'l', 'o', 'a', 'd', 'a', 'b', 'l', 'e', ' ', 'c', 'o', 'n', 't', 'e', 'n', 't', ' ', ',', ' ', 'a', 'l', 'o', 'n', 'g', ' ', 'w', 'i', 't', 'h', ' ', 'a', 'n', ' ', 'e', 'x', 'p', 'a', 'n', 'd', 'e', 'd', ' ', 'e', 'd', 'i', 't', 'i', 'o', 'n', ' ', 'i', 'n', ' ', 'n', 'o', 'v', 'e', 'm', 'b', 'e', 'r', ' ', 'o', 'f', ' ', 't', 'h', 'a', 't', ' ', 'y', 'e', 'a', 'r', ' ', '.', ' ', 'i', 't', ' ', 'w', 'a', 's', ' ', 'a', 'l', 's', 'o', ' ', 'a', 'd', 'a', 'p', 't', 'e', 'd', ' ', 'i', 'n', 't', 'o', ' ', 'm', 'a', 'n', 'g', 'a', ' ', 'a', 'n', 'd', ' ', 'a', 'n', ' ', 'o', 'r', 'i', 'g', 'i', 'n', 'a', 'l', ' ', 'v', 'i', 'd', 'e', 'o', ' ', 'a', 'n', 'i', 'm', 'a', 't', 'i', 'o', 'n', ' ', 's', 'e', 'r', 'i', 'e', 's', ' ', '.', ' ', 'd', 'u', 'e', ' ', 't', 'o', ' ', 'l', 'o', 'w', ' ', 's', 'a', 'l', 'e', 's', ' ', 'o', 'f', ' ', 'v', 'a', 'l', 'k', 'y', 'r', 'i', 'a', ' ', 'c', 'h', 'r', 'o', 'n', 'i', 'c', 'l', 'e', 's', ' ', 'i', 'i', ' ', ',', ' ', 'v', 'a', 'l', 'k', 'y', 'r', 'i', 'a', ' ', 'c', 'h', 'r', 'o', 'n', 'i', 'c', 'l', 'e', 's', ' ', 'i', 'i', 'i', ' ', 'w', 'a', 's', ' ', 'n', 'o', 't', ' ', 'l', 'o', 'c', 'a', 'l', 'i', 'z', 'e', 'd', ' ', ',', ' ', 'b', 'u', 't', ' ', 'a', ' ', 'f', 'a', 'n', ' ', 't', 'r', 'a', 'n', 's', 'l', 'a', 't', 'i', 'o', 'n', ' ', 'c', 'o', 'm', 'p', 'a', 't', 'i', 'b', 'l', 'e', ' ', 'w', 'i', 't', 'h', ' ', 't', 'h', 'e', ' ', 'g', 'a', 'm', 'e', ' ', \"'\", 's', ' ', 'e', 'x', 'p', 'a', 'n', 'd', 'e', 'd', ' ', 'e', 'd', 'i', 't', 'i', 'o', 'n', ' ', 'w', 'a', 's', ' ', 'r', 'e', 'l', 'e', 'a', 's', 'e', 'd', ' ', 'i', 'n', ' ', '2', '0', '1', '4', ' ', '.', ' ', 'm', 'e', 'd', 'i', 'a', '.', 'v', 'i', 's', 'i', 'o', 'n', ' ', 'w', 'o', 'u', 'l', 'd', ' ', 'r', 'e', 't', 'u', 'r', 'n', ' ', 't', 'o', ' ', 't', 'h', 'e', ' ', 'f', 'r', 'a', 'n', 'c', 'h', 'i', 's', 'e', ' ', 'w', 'i', 't', 'h', ' ', 't', 'h', 'e', ' ', 'd', 'e', 'v', 'e', 'l', 'o', 'p', 'm', 'e', 'n', 't', ' ', 'o', 'f', ' ', 'v', 'a', 'l', 'k', 'y', 'r', 'i', 'a', ' ', ':', ' ', 'a', 'z', 'u', 'r', 'e', ' ', 'r', 'e', 'v', 'o', 'l', 'u', 't', 'i', 'o', 'n', ' ', 'f', 'o', 'r', ' ', 't', 'h', 'e', ' ', 'p', 'l', 'a', 'y', 's', 't', 'a', 't', 'i', 'o', 'n', ' ', '4', ' ', '.']\n",
      "\n",
      "Texto 5: = = Gameplay = =\n",
      "Tokenizada por caracteres 5: ['=', ' ', '=', ' ', 'g', 'a', 'm', 'e', 'p', 'l', 'a', 'y', ' ', '=', ' ', '=']\n"
     ]
    }
   ],
   "source": [
    "# Creamos una lista donde cada oración está representada como una lista de caracteres en minúscula\n",
    "tokenized_sentences_by_char = [list(sentence.lower().strip()) for sentence in sentences]\n",
    "\n",
    "# Mostramos ejemplo de una oración tokenizada\n",
    "for i in range(5):\n",
    "    print(f\"\\nTexto {i+1}: {sentences[i]}\")\n",
    "    print(f\"Tokenizada por caracteres {i+1}: {tokenized_sentences_by_char[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "874f762d-4f80-4115-a00b-0e3df92d4b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total de caracteres únicos en el vocabulario: 54\n",
      "\n",
      "Vocabulario inicial (caracteres):\n",
      "' ': 324\n",
      "'e': 168\n",
      "'a': 149\n",
      "'i': 130\n",
      "'t': 108\n",
      "'n': 104\n",
      "'o': 96\n",
      "'r': 95\n",
      "'s': 84\n",
      "'l': 72\n",
      "'d': 52\n",
      "'h': 49\n",
      "'c': 38\n",
      "'m': 38\n",
      "'p': 35\n",
      "'g': 30\n",
      "'v': 26\n",
      "'y': 26\n",
      "'u': 26\n",
      "'f': 24\n",
      "'w': 23\n",
      "'k': 18\n",
      "'.': 16\n",
      "',': 15\n",
      "'b': 13\n",
      "'j': 9\n",
      "'=': 6\n",
      "'@': 4\n",
      "'0': 4\n",
      "'1': 4\n",
      "'\"': 4\n",
      "'3': 3\n",
      "':': 3\n",
      "'<': 3\n",
      "'>': 3\n",
      "'2': 3\n",
      "'z': 3\n",
      "''': 3\n",
      "'-': 2\n",
      "'x': 2\n",
      "'4': 2\n",
      "'ō': 1\n",
      "'(': 1\n",
      "'戦': 1\n",
      "'場': 1\n",
      "'の': 1\n",
      "'ヴ': 1\n",
      "'ァ': 1\n",
      "'ル': 1\n",
      "'キ': 1\n",
      "'ュ': 1\n",
      "'リ': 1\n",
      "'ア': 1\n",
      "')': 1\n"
     ]
    }
   ],
   "source": [
    "# Construimos un vocabulario a partir de los caracteres tokenizados\n",
    "char_vocab = Counter()\n",
    "\n",
    "for sentence in tokenized_sentences_by_char:\n",
    "    char_vocab.update(sentence)\n",
    "\n",
    "# Mostramos el tamaño del vocabulario y los caracteres más frecuentes\n",
    "print(f\"\\nTotal de caracteres únicos en el vocabulario: {len(char_vocab)}\")\n",
    "print(\"\\nVocabulario inicial (caracteres):\")\n",
    "for char, freq in char_vocab.most_common():\n",
    "    print(f\"'{char}': {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f2830b-f4f8-4d79-8123-2a0e2269ed39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
