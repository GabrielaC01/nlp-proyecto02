{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cf2bac5-773f-4772-8b34-472d096a07ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/jovyan/work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dedd3a3-743a-4fe5-a5f5-65d97313e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from src.data_loader import cargar_dataset, tokenize_sentences_by_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fba347ed-84b6-423c-a944-a0c946eefdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el modelo RNN\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        # Capa de embedding\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # Capa LSTM\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        # Capa de salida\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.rnn(x)\n",
    "        out = out[:, -1, :]  # Usamos la última salida del RNN\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de337037-d713-48fd-a060-2c015c5b931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar el modelo\n",
    "def train_model(model, train_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            data, targets = batch\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3af462cf-5662-4180-aff6-7d4fb3b6db9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para evaluar el modelo\n",
    "def evaluate_model(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            data, targets = batch\n",
    "            output = model(data)\n",
    "            loss = criterion(output, targets)\n",
    "            total_loss += loss.item()\n",
    "    print(f\"Validation Loss: {total_loss/len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "997fb51a-45e5-42de-9162-a5dacb3471d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos parámetros\n",
    "embedding_dim = 100\n",
    "hidden_dim = 128\n",
    "output_size = 2  # Por ejemplo, 2 clases (o ajusta según tu tarea)\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bcc178a6-beda-45d3-ac8c-cd332cee5286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 1801350\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 3760\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el dataset\n",
    "train_data = cargar_dataset(split=\"train\")\n",
    "print(train_data)  \n",
    "\n",
    "val_data = cargar_dataset(split=\"validation\")\n",
    "print(val_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "631a4019-a49d-4d51-82ec-8bcda4793e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', ' = Valkyria Chronicles III = \\n', '', ' Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" <unk> Raven \" . \\n', \" The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer <unk> Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \\n\"]\n",
      "['', ' = Homarus gammarus = \\n', '', ' Homarus gammarus , known as the European lobster or common lobster , is a species of clawed lobster from the eastern Atlantic Ocean , Mediterranean Sea and parts of the Black Sea . It is closely related to the American lobster , H. americanus . It may grow to a length of 60 cm ( 24 in ) and a mass of 6 kilograms ( 13 lb ) , and bears a conspicuous pair of claws . In life , the lobsters are blue , only becoming \" lobster red \" on cooking . Mating occurs in the summer , producing eggs which are carried by the females for up to a year before hatching into planktonic larvae . Homarus gammarus is a highly esteemed food , and is widely caught using lobster pots , mostly around the British Isles . \\n', '']\n"
     ]
    }
   ],
   "source": [
    "# Extraemos las oraciones de la columna 'text'\n",
    "train_sentences = train_data['text']\n",
    "val_sentences = val_data['text']\n",
    "\n",
    "# Imprimimos un ejemplo para ver si se cargaron correctamente\n",
    "print(train_sentences[:5])  \n",
    "print(val_sentences[:5])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54ebce4-67de-4b8e-beda-e480e09a1d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenización y conversión a tensores\n",
    "train_data = tokenize_sentences_by_char(train_sentences)\n",
    "val_data = tokenize_sentences_by_char(val_sentences)\n",
    "\n",
    "# Crear DataLoader\n",
    "train_loader = DataLoader(list(zip(train_data)), batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(list(zip(val_data)), batch_size=64, shuffle=False)\n",
    "\n",
    "# Inicializamos el modelo, el criterio y el optimizador\n",
    "vocab_size = len(set([char for sentence in train_data for char in sentence])) \n",
    "model = RNNModel(vocab_size, embedding_dim, hidden_dim, output_size)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entrenamos el modelo\n",
    "train_model(model, train_loader, criterion, optimizer, epochs=epochs)\n",
    "\n",
    "# Evaluamos el modelo\n",
    "evaluate_model(model, val_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeea79f-3595-4ec4-9a6e-1672d817819d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
